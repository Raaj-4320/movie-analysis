{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ca4ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromedriver_autoinstaller in c:\\users\\rajgo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\rajgo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromedriver_autoinstaller) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdc527d-f9ac-4f16-9c25-d906c7aee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_genres = ['action',\n",
    "                  'adventure',\n",
    "                  'animation',\n",
    "                  'biography',\n",
    "                  'comedy',\n",
    "                  'crime',\n",
    "                  'documentry',\n",
    "                  'drama',\n",
    "                  'family',\n",
    "                  'fantasy',\n",
    "                  'history',\n",
    "                  'horror',\n",
    "                  'music',\n",
    "                  'romance',\n",
    "                  'mystery',\n",
    "                  'thriller',\n",
    "                  'war',\n",
    "                  'western',\n",
    "                  'sport',\n",
    "                  'sci-fi',\n",
    "                  'game-show',\n",
    "                  'film-noir']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437fdd4-912f-43fc-8071-1f4e0103ce89",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Get links of movie from ONE particular genre ('action in this case')"
=======
    "# Below code fetches the movie links of a particular genre"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364225ac-939c-4e30-86a6-76758652a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "import time\n",
    "\n",
    "# Automatically install the correct version of chromedriver that matches the installed Chrome version\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Chrome options to set user-agent\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Function to extract movie links from a genre page\n",
    "def extract_movie_links(genre):\n",
    "    url = f'https://www.imdb.com/search/title/?genres={genre}&explore=genres&title_type=feature'\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Wait until at least one movie link element is visible\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'ipc-title-link-wrapper')))\n",
    "    except TimeoutException:\n",
    "        print(f'Timeout waiting for {url} to load')\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return []\n",
    "\n",
    "    time.sleep(2)  # Additional delay to ensure page stability\n",
    "    \n",
    "    movie_links = []\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "    \n",
    "    for link_element in link_elements:\n",
    "        href = link_element['href']\n",
    "        full_url = f'https://www.imdb.com{href}'\n",
    "        movie_id = href.split('/')[2].split('?')[0]  # Extract movie ID from URL\n",
    "        movie_links.append({\n",
    "            'Genre': genre,\n",
    "            'Movie ID': movie_id,\n",
    "            'Movie URL': full_url\n",
    "        })\n",
    "    \n",
    "    return movie_links\n",
    "\n",
    "# Scrape movie links for the \"action\" genre\n",
    "genre = 'action'\n",
    "action_movie_links = extract_movie_links(genre)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
<<<<<<< HEAD
    "action_links_df = pd.DataFrame(action_movie_links)\n",
    "\n"
=======
    "action_links_df = pd.DataFrame(action_movie_links)"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18face4e-3624-41ef-b761-72022e4e00c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>tt4919268</td>\n",
       "      <td>https://www.imdb.com/title/tt4919268/?ref_=sr_t_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action</td>\n",
       "      <td>tt12037194</td>\n",
       "      <td>https://www.imdb.com/title/tt12037194/?ref_=sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action</td>\n",
       "      <td>tt13964390</td>\n",
       "      <td>https://www.imdb.com/title/tt13964390/?ref_=sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>action</td>\n",
       "      <td>tt1684562</td>\n",
       "      <td>https://www.imdb.com/title/tt1684562/?ref_=sr_t_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>action</td>\n",
       "      <td>tt23289160</td>\n",
       "      <td>https://www.imdb.com/title/tt23289160/?ref_=sr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Genre    Movie ID                                          Movie URL\n",
       "0  action   tt4919268  https://www.imdb.com/title/tt4919268/?ref_=sr_t_1\n",
       "1  action  tt12037194  https://www.imdb.com/title/tt12037194/?ref_=sr...\n",
       "2  action  tt13964390  https://www.imdb.com/title/tt13964390/?ref_=sr...\n",
       "3  action   tt1684562  https://www.imdb.com/title/tt1684562/?ref_=sr_t_4\n",
       "4  action  tt23289160  https://www.imdb.com/title/tt23289160/?ref_=sr..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646e9a1-070d-4246-a244-dd621b68511c",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# 2. Movie Genres links"
=======
    "# 2. Below code get the movie links of all the user defined genre"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f982ad-2446-4cdd-b50f-f52e9dbcf909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout waiting for https://www.imdb.com/search/title/?genres=documentry&explore=genres&title_type=feature to load\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException  # Import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "import time\n",
    "\n",
    "# Automatically install the correct version of chromedriver that matches the installed Chrome version\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Chrome options to set user-agent\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Function to extract movie links from a genre page\n",
    "def extract_movie_links(genre):\n",
    "    url = f'https://www.imdb.com/search/title/?genres={genre}&explore=genres&title_type=feature'\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Wait until at least one movie link element is visible\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'ipc-title-link-wrapper')))\n",
    "    except TimeoutException:\n",
    "        print(f'Timeout waiting for {url} to load')\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return []\n",
    "\n",
    "    time.sleep(2)  # Additional delay to ensure page stability\n",
    "    \n",
    "    movie_links = []\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "    \n",
    "    for link_element in link_elements:\n",
    "        href = link_element['href']\n",
    "        full_url = f'https://www.imdb.com{href}'\n",
    "        movie_id = href.split('/')[2].split('?')[0]  # Extract movie ID from URL\n",
    "        movie_links.append({\n",
    "            'Genre': genre,\n",
    "            'Movie ID': movie_id,\n",
    "            'Movie URL': full_url\n",
    "        })\n",
    "    \n",
    "    return movie_links\n",
    "\n",
    "# List of genres to scrape\n",
    "list_of_genres = ['action',\n",
    "                  'adventure',\n",
    "                  'animation',\n",
    "                  'biography',\n",
    "                  'comedy',\n",
    "                  'crime',\n",
    "                  'documentry',\n",
    "                  'drama',\n",
    "                  'family',\n",
    "                  'fantasy',\n",
    "                  'history',\n",
    "                  'horror',\n",
    "                  'music',\n",
    "                  'romance',\n",
    "                  'mystery',\n",
    "                  'thriller',\n",
    "                  'war',\n",
    "                  'western',\n",
    "                  'sport',\n",
    "                  'sci-fi',\n",
    "                  'game-show',\n",
    "                  'film-noir'] # Add more genres as needed\n",
    "\n",
    "# Data storage list\n",
    "data_list = []\n",
    "\n",
    "# Iterate over each genre and extract movie links\n",
    "for genre in list_of_genres:\n",
    "    genre_movie_links = extract_movie_links(genre)\n",
    "    data_list.extend(genre_movie_links)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "all_genre_links_df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b2a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>tt4919268</td>\n",
       "      <td>https://www.imdb.com/title/tt4919268/?ref_=sr_t_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action</td>\n",
       "      <td>tt12037194</td>\n",
       "      <td>https://www.imdb.com/title/tt12037194/?ref_=sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action</td>\n",
       "      <td>tt13964390</td>\n",
       "      <td>https://www.imdb.com/title/tt13964390/?ref_=sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>action</td>\n",
       "      <td>tt1684562</td>\n",
       "      <td>https://www.imdb.com/title/tt1684562/?ref_=sr_t_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>action</td>\n",
       "      <td>tt23289160</td>\n",
       "      <td>https://www.imdb.com/title/tt23289160/?ref_=sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>film-noir</td>\n",
       "      <td>tt0034248</td>\n",
       "      <td>https://www.imdb.com/title/tt0034248/?ref_=sr_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>film-noir</td>\n",
       "      <td>tt0044136</td>\n",
       "      <td>https://www.imdb.com/title/tt0044136/?ref_=sr_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>film-noir</td>\n",
       "      <td>tt0048261</td>\n",
       "      <td>https://www.imdb.com/title/tt0048261/?ref_=sr_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>film-noir</td>\n",
       "      <td>tt0051207</td>\n",
       "      <td>https://www.imdb.com/title/tt0051207/?ref_=sr_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>film-noir</td>\n",
       "      <td>tt0049552</td>\n",
       "      <td>https://www.imdb.com/title/tt0049552/?ref_=sr_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre    Movie ID                                          Movie URL\n",
       "0        action   tt4919268  https://www.imdb.com/title/tt4919268/?ref_=sr_t_1\n",
       "1        action  tt12037194  https://www.imdb.com/title/tt12037194/?ref_=sr...\n",
       "2        action  tt13964390  https://www.imdb.com/title/tt13964390/?ref_=sr...\n",
       "3        action   tt1684562  https://www.imdb.com/title/tt1684562/?ref_=sr_t_4\n",
       "4        action  tt23289160  https://www.imdb.com/title/tt23289160/?ref_=sr...\n",
       "...         ...         ...                                                ...\n",
       "1026  film-noir   tt0034248  https://www.imdb.com/title/tt0034248/?ref_=sr_...\n",
       "1027  film-noir   tt0044136  https://www.imdb.com/title/tt0044136/?ref_=sr_...\n",
       "1028  film-noir   tt0048261  https://www.imdb.com/title/tt0048261/?ref_=sr_...\n",
       "1029  film-noir   tt0051207  https://www.imdb.com/title/tt0051207/?ref_=sr_...\n",
       "1030  film-noir   tt0049552  https://www.imdb.com/title/tt0049552/?ref_=sr_...\n",
       "\n",
       "[1031 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genre_links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa33a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genre_links_df.to_csv('all_movie_genre_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6136061-5f71-461f-85d1-bca03f1e4865",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Get data of movie from one particular link"
=======
    "# 3. Below code Get data of movie from one particular link"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bfe9449-6ebe-44eb-aa07-1b6a630b45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "# Automatically install the correct version of chromedriver that matches the installed Chrome version\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Chrome options to set user-agent\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# List of URLs (example: movie_links should be defined)\n",
    "movie_links = [\"https://www.imdb.com/title/tt0266697/?ref_=sr_t_49\"]\n",
    "\n",
    "# Data storage list\n",
    "data_list = []\n",
    "\n",
    "for url in movie_links:\n",
    "    # Open the IMDb page for the movie\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait until the page title contains \"IMDb\"\n",
    "    WebDriverWait(driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Function to extract text including pseudo-elements\n",
    "    def get_text_with_pseudo(driver, element):\n",
    "        script = \"\"\"\n",
    "        var element = arguments[0];\n",
    "        var before = window.getComputedStyle(element, '::before').getPropertyValue('content');\n",
    "        var text = element.textContent;\n",
    "        return before.replace(/\"/g, '') + text;\n",
    "        \"\"\"\n",
    "        return driver.execute_script(script, element).strip()\n",
    "\n",
    "    # Extract the required information using BeautifulSoup\n",
    "    title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "    imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "    # Principal credits section\n",
    "    credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "\n",
    "    directors = []\n",
    "    for elem in credits_section[0].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            directors.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            directors.append('N/A')\n",
    "\n",
    "    writers = []\n",
    "    for elem in credits_section[1].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            writers.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            writers.append('N/A')\n",
    "\n",
    "    stars = []\n",
    "    for elem in credits_section[2].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            stars.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            stars.append('N/A')\n",
    "\n",
    "    storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "\n",
    "    # Release date with pseudo-element\n",
    "    release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "    release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "    origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "    languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "    budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "    gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "    runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "    # Extract genres\n",
    "    genres = []\n",
    "    genres_container = soup.find('div', {'data-testid': 'genres'})\n",
    "    if genres_container:\n",
    "        genre_links = genres_container.find_all('a')\n",
    "        genres = [link.text.strip() for link in genre_links]\n",
    "\n",
    "    # Extract movie_id from URL\n",
    "    movie_id = url.split('/')[4]\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    movie_data = {\n",
    "        \"Movie ID\": movie_id,\n",
    "        \"Title\": title,\n",
    "        \"IMDB Rating\": imdb_rating,\n",
    "        \"Directors\": \", \".join(directors),\n",
    "        \"Writers\": \", \".join(writers),\n",
    "        \"Stars\": \", \".join(stars),\n",
    "        \"Storyline\": storyline,\n",
    "        \"Release Date\": release_date,\n",
    "        \"Origin Countries\": \", \".join(origin_countries),\n",
    "        \"Languages\": \", \".join(languages),\n",
    "        \"Budget\": budget,\n",
    "        \"Gross Worldwide\": gross_worldwide,\n",
    "        \"Runtime\": runtime,\n",
    "        \"Genres\": \", \".join(genres)\n",
    "    }\n",
    "\n",
    "    # Append data to the list\n",
    "    data_list.append(movie_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "one_movie_df = pd.DataFrame(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7786af90-c180-4f10-86db-341015c15bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Directors</th>\n",
       "      <th>Writers</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Storyline</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Origin Countries</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Gross Worldwide</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0266697</td>\n",
       "      <td>Kill Bill: Vol. 1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>​Quentin Tarantino</td>\n",
       "      <td>noneWriters, ​Quentin Tarantino, ​Uma Thurman,...</td>\n",
       "      <td>noneStars, ​Uma Thurman, ​David Carradine, ​Da...</td>\n",
       "      <td>After awakening from a four-year coma, a forme...</td>\n",
       "      <td>Release date</td>\n",
       "      <td>United States, China</td>\n",
       "      <td>English, Japanese, French</td>\n",
       "      <td>$30,000,000 (estimated)</td>\n",
       "      <td>$180,908,413</td>\n",
       "      <td>1 hour 51 minutes</td>\n",
       "      <td>Action, Crime, Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Movie ID              Title IMDB Rating           Directors  \\\n",
       "0  tt0266697  Kill Bill: Vol. 1         8.2  ​Quentin Tarantino   \n",
       "\n",
       "                                             Writers  \\\n",
       "0  noneWriters, ​Quentin Tarantino, ​Uma Thurman,...   \n",
       "\n",
       "                                               Stars  \\\n",
       "0  noneStars, ​Uma Thurman, ​David Carradine, ​Da...   \n",
       "\n",
       "                                           Storyline  Release Date  \\\n",
       "0  After awakening from a four-year coma, a forme...  Release date   \n",
       "\n",
       "       Origin Countries                  Languages                   Budget  \\\n",
       "0  United States, China  English, Japanese, French  $30,000,000 (estimated)   \n",
       "\n",
       "  Gross Worldwide            Runtime                   Genres  \n",
       "0    $180,908,413  1 hour 51 minutes  Action, Crime, Thriller  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_movie_df"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c2fd3-0f48-43af-af3c-cd02d91989ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
=======
>>>>>>> master
   "cell_type": "markdown",
   "id": "b52f62cf-bf33-4f47-bc7a-c9730154dc26",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Below code gets data from all the movie links that we scrapped"
=======
    "# 4. Below code gets data from all the movie links that we scrapped"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "93ee62e3-ea63-430f-a43c-5c68e5c6a2e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Wait until the page title contains \"IMDb\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mtitle_contains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the page source and parse it with BeautifulSoup\u001b[39;00m\n\u001b[0;32m     30\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
=======
   "metadata": {},
   "outputs": [],
>>>>>>> master
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
<<<<<<< HEAD
=======
    "import logging\n",
>>>>>>> master
    "\n",
    "# Automatically install the correct version of chromedriver that matches the installed Chrome version\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Chrome options to set user-agent\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
<<<<<<< HEAD
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# List of URLs (example: movie_links should be defined)\n",
    "movie_links = [\"https://www.imdb.com/title/tt0266697/?ref_=sr_t_49\"]\n",
    "\n",
    "# Data storage list\n",
    "# data_list = []\n",
    "\n",
    "for url in all_genre_links_df['Movie URL']:\n",
    "    # Open the IMDb page for the movie\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait until the page title contains \"IMDb\"\n",
    "        WebDriverWait(driver, 20).until(EC.title_contains(\"IMDb\"))\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout waiting for {url} to load IMDb page title\")\n",
    "        driver.quit()\n",
    "        continue  # Skip to the next movie URL or handle the error appropriately\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "    # Function to extract text including pseudo-elements\n",
    "    def get_text_with_pseudo(driver, element):\n",
    "        script = \"\"\"\n",
    "        var element = arguments[0];\n",
    "        var before = window.getComputedStyle(element, '::before').getPropertyValue('content');\n",
    "        var text = element.textContent;\n",
    "        return before.replace(/\"/g, '') + text;\n",
    "        \"\"\"\n",
    "        return driver.execute_script(script, element).strip()\n",
    "\n",
    "    # Extract the required information using BeautifulSoup\n",
    "    title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "    imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "    # Principal credits section\n",
    "    credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "\n",
    "    directors = []\n",
    "    for elem in credits_section[0].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            directors.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            directors.append('N/A')\n",
    "\n",
    "    writers = []\n",
    "    for elem in credits_section[1].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            writers.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            writers.append('N/A')\n",
    "\n",
    "    stars = []\n",
    "    for elem in credits_section[2].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            stars.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            stars.append('N/A')\n",
    "\n",
    "    storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "\n",
    "    # Release date with pseudo-element\n",
    "    release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "    release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "    origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "    languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "    budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "    gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "    runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "    # Extract genres\n",
    "    genres = []\n",
    "    genres_container = soup.find('div', {'data-testid': 'genres'})\n",
    "    if genres_container:\n",
    "        genre_links = genres_container.find_all('a')\n",
    "        genres = [link.text.strip() for link in genre_links]\n",
    "\n",
    "    # Extract movie_id from URL\n",
    "    movie_id = url.split('/')[4]\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    movie_data = {\n",
    "        \"Movie ID\": movie_id,\n",
    "        \"Title\": title,\n",
    "        \"IMDB Rating\": imdb_rating,\n",
    "        \"Directors\": \", \".join(directors),\n",
    "        \"Writers\": \", \".join(writers),\n",
    "        \"Stars\": \", \".join(stars),\n",
    "        \"Storyline\": storyline,\n",
    "        \"Release Date\": release_date,\n",
    "        \"Origin Countries\": \", \".join(origin_countries),\n",
    "        \"Languages\": \", \".join(languages),\n",
    "        \"Budget\": budget,\n",
    "        \"Gross Worldwide\": gross_worldwide,\n",
    "        \"Runtime\": runtime,\n",
    "        \"Genres\": \", \".join(genres)\n",
    "    }\n",
    "\n",
    "    # Append data to the list\n",
    "    data_list.append(movie_data)\n",
=======
    "# Set up logging\n",
    "logging.basicConfig(filename='scraping_errors.log', level=logging.ERROR)\n",
    "\n",
    "# Function to initialize WebDriver\n",
    "def init_driver():\n",
    "    return webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = init_driver()\n",
    "\n",
    "# Data storage list\n",
    "data_list = []\n",
    "\n",
    "# Start from the 329th link (index 328, as Python uses 0-based indexing)\n",
    "for url in all_genre_links_df['Movie URL']:\n",
    "    try:\n",
    "        # Open the IMDb page for the movie\n",
    "        driver.get(url)\n",
    "\n",
    "        try:\n",
    "            # Wait until the page title contains \"IMDb\"\n",
    "            WebDriverWait(driver, 20).until(EC.title_contains(\"IMDb\"))\n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Timeout waiting for {url} to load IMDb page title\")\n",
    "            continue  # Skip to the next movie URL or handle the error appropriately\n",
    "\n",
    "        # Get the page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Function to extract text including pseudo-elements\n",
    "        def get_text_with_pseudo(driver, element):\n",
    "            script = \"\"\"\n",
    "            var element = arguments[0];\n",
    "            var before = window.getComputedStyle(element, '::before').getPropertyValue('content');\n",
    "            var text = element.textContent;\n",
    "            return before.replace(/\"/g, '') + text;\n",
    "            \"\"\"\n",
    "            return driver.execute_script(script, element).strip()\n",
    "\n",
    "        # Extract the required information using BeautifulSoup\n",
    "        title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "        imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "        # Principal credits section\n",
    "        credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "\n",
    "        directors = []\n",
    "        for elem in credits_section[0].find_all('a'):\n",
    "            try:\n",
    "                element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "                directors.append(get_text_with_pseudo(driver, element))\n",
    "            except Exception as e:\n",
    "                directors.append('N/A')\n",
    "\n",
    "        writers = []\n",
    "        for elem in credits_section[1].find_all('a'):\n",
    "            try:\n",
    "                element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "                writers.append(get_text_with_pseudo(driver, element))\n",
    "            except Exception as e:\n",
    "                writers.append('N/A')\n",
    "\n",
    "        stars = []\n",
    "        for elem in credits_section[2].find_all('a'):\n",
    "            try:\n",
    "                element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "                stars.append(get_text_with_pseudo(driver, element))\n",
    "            except Exception as e:\n",
    "                stars.append('N/A')\n",
    "\n",
    "        storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "\n",
    "        # Release date with pseudo-element\n",
    "        release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "        release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "        origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "        languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "        budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "        gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "        runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "        # Extract genres\n",
    "        genres = []\n",
    "        genres_container = soup.find('div', {'data-testid': 'genres'})\n",
    "        if genres_container:\n",
    "            genre_links = genres_container.find_all('a')\n",
    "            genres = [link.text.strip() for link in genre_links]\n",
    "\n",
    "        # Extract movie_id from URL\n",
    "        movie_id = url.split('/')[4]\n",
    "\n",
    "        # Store data in a dictionary\n",
    "        movie_data = {\n",
    "            \"Movie ID\": movie_id,\n",
    "            \"Title\": title,\n",
    "            \"IMDB Rating\": imdb_rating,\n",
    "            \"Directors\": \", \".join(directors),\n",
    "            \"Writers\": \", \".join(writers),\n",
    "            \"Stars\": \", \".join(stars),\n",
    "            \"Storyline\": storyline,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Origin Countries\": \", \".join(origin_countries),\n",
    "            \"Languages\": \", \".join(languages),\n",
    "            \"Budget\": budget,\n",
    "            \"Gross Worldwide\": gross_worldwide,\n",
    "            \"Runtime\": runtime,\n",
    "            \"Genres\": \", \".join(genres)\n",
    "        }\n",
    "\n",
    "        # Append data to the list\n",
    "        data_list.append(movie_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping {url}: {str(e)}\")\n",
    "        # Restart the WebDriver in case of critical error\n",
    "        driver.quit()\n",
    "        driver = init_driver()\n",
>>>>>>> master
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
<<<<<<< HEAD
    "one_movie_df = pd.DataFrame(data_list)\n"
=======
    "all_movie_details = pd.DataFrame(data_list)\n",
    "\n"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "5b61962f-aeb9-4d7d-9a45-50c409efd67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19b53a-663b-4e07-90f7-b8c5f863b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> master
   "id": "20380ecf-9944-422d-905e-beec9da493ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438170a4-3ae2-4272-b791-aeb6f13cf62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30967f-ed62-497b-ad2b-8ba7ce68b325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2b5a9-6212-4e5e-9818-d0ea0ea10643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3f834-7ae7-46b2-b763-fe9b8e3c8485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11efa10-afd2-4bd2-85af-affe950242ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f2d56-84f7-4cb2-8359-2bbf4a2a44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No movie links found.\n",
      "No data scraped.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "class IMDbScraper:\n",
    "    def __init__(self):\n",
    "        # Chrome service and options\n",
    "        chromedriver_autoinstaller.install()\n",
    "        self.chrome_options = ChromeOptions()\n",
    "        self.chrome_options.add_argument(\"--headless\")  # Run in headless mode for faster execution\n",
    "        self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "\n",
    "    def fetch_action_movie_links(self, url, num_links=50):\n",
    "        self.driver.get(url)\n",
    "        movie_links = []\n",
    "        while len(movie_links) < num_links:\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "            for link_element in link_elements:\n",
    "                href = link_element['href']\n",
    "                full_url = f'https://www.imdb.com{href}'\n",
    "                if full_url not in movie_links:\n",
    "                    movie_links.append(full_url)\n",
    "                if len(movie_links) >= num_links:\n",
    "                    break\n",
    "            try:\n",
    "                next_button = self.driver.find_element(By.XPATH, \"//a[contains(text(),'Next »')]\")\n",
    "                next_button.click()\n",
    "            except:\n",
    "                break\n",
    "        return movie_links\n",
    "\n",
    "    def get_movie_details(self, url):\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "        title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "        imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "        credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "        directors = [a.text.strip() for a in credits_section[0].find_all('a')] if len(credits_section) > 0 else []\n",
    "        writers = [a.text.strip() for a in credits_section[1].find_all('a')] if len(credits_section) > 1 else []\n",
    "        stars = [a.text.strip() for a in credits_section[2].find_all('a')] if len(credits_section) > 2 else []\n",
    "\n",
    "        storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "        release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "        release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "        origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "        languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "        budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "        gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "        runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "        genres = [link.text.strip() for link in soup.find('div', {'data-testid': 'genres'}).find_all('a')] if soup.find('div', {'data-testid': 'genres'}) else []\n",
    "\n",
    "        movie_data = {\n",
    "            \"Title\": title,\n",
    "            \"IMDB Rating\": imdb_rating,\n",
    "            \"Directors\": \", \".join(directors),\n",
    "            \"Writers\": \", \".join(writers),\n",
    "            \"Stars\": \", \".join(stars),\n",
    "            \"Storyline\": storyline,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Origin Countries\": \", \".join(origin_countries),\n",
    "            \"Languages\": \", \".join(languages),\n",
    "            \"Budget\": budget,\n",
    "            \"Gross Worldwide\": gross_worldwide,\n",
    "            \"Runtime\": runtime,\n",
    "            \"Genres\": \", \".join(genres)\n",
    "        }\n",
    "\n",
    "        return movie_data\n",
    "\n",
    "    def scrape_movies(self, url, num_links=50):\n",
    "        movie_links = self.fetch_action_movie_links(url, num_links)\n",
    "        if not movie_links:\n",
    "            print(\"No movie links found.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data_list = []\n",
    "        for link in movie_links:\n",
    "            movie_data = self.get_movie_details(link)\n",
    "            data_list.append(movie_data)\n",
    "\n",
    "        self.driver.quit()\n",
    "        return pd.DataFrame(data_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = IMDbScraper()\n",
    "    action_movies_url = 'https://www.imdb.com/search/title/?genres=action&explore=genres&title_type=feature'\n",
    "    movie_df = scraper.scrape_movies(action_movies_url, num_links=50)\n",
    "    if movie_df.empty:\n",
    "        print(\"No data scraped.\")\n",
    "    else:\n",
    "        print(movie_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d141c-260c-4a69-a999-d7c2df17ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "class IMDbScraper:\n",
    "    def __init__(self):\n",
    "        chromedriver_autoinstaller.install()\n",
    "        self.chrome_options = ChromeOptions()\n",
    "        self.chrome_options.add_argument(\"--headless\")\n",
    "        self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "\n",
    "    def fetch_action_movie_links(self, url, num_links=50):\n",
    "        self.driver.get(url)\n",
    "        movie_links = []\n",
    "        while len(movie_links) < num_links:\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            link_elements = soup.select('h3.lister-item-header a')\n",
    "            for link_element in link_elements:\n",
    "                href = link_element['href']\n",
    "                full_url = f'https://www.imdb.com{href}'\n",
    "                if full_url not in movie_links:\n",
    "                    movie_links.append(full_url)\n",
    "                if len(movie_links) >= num_links:\n",
    "                    break\n",
    "            try:\n",
    "                next_button = self.driver.find_element(By.XPATH, \"//a[contains(text(),'Next »')]\")\n",
    "                next_button.click()\n",
    "            except Exception as e:\n",
    "                print(f\"Error finding next button or clicking it: {e}\")\n",
    "                break\n",
    "        return movie_links\n",
    "\n",
    "    def get_movie_details(self, url):\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "        title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "        imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "        credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "        directors = [a.text.strip() for a in credits_section[0].find_all('a')] if len(credits_section) > 0 else []\n",
    "        writers = [a.text.strip() for a in credits_section[1].find_all('a')] if len(credits_section) > 1 else []\n",
    "        stars = [a.text.strip() for a in credits_section[2].find_all('a')] if len(credits_section) > 2 else []\n",
    "\n",
    "        storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "        release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "        release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "        origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "        languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "        budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "        gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "        runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "        genres = [link.text.strip() for link in soup.find('div', {'data-testid': 'genres'}).find_all('a')] if soup.find('div', {'data-testid': 'genres'}) else []\n",
    "\n",
    "        movie_data = {\n",
    "            \"Title\": title,\n",
    "            \"IMDB Rating\": imdb_rating,\n",
    "            \"Directors\": \", \".join(directors),\n",
    "            \"Writers\": \", \".join(writers),\n",
    "            \"Stars\": \", \".join(stars),\n",
    "            \"Storyline\": storyline,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Origin Countries\": \", \".join(origin_countries),\n",
    "            \"Languages\": \", \".join(languages),\n",
    "            \"Budget\": budget,\n",
    "            \"Gross Worldwide\": gross_worldwide,\n",
    "            \"Runtime\": runtime,\n",
    "            \"Genres\": \", \".join(genres)\n",
    "        }\n",
    "\n",
    "        return movie_data\n",
    "\n",
    "    def scrape_movies(self, url, num_links=50):\n",
    "        movie_links = self.fetch_action_movie_links(url, num_links)\n",
    "        if not movie_links:\n",
    "            print(\"No movie links found.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data_list = []\n",
    "        for link in movie_links:\n",
    "            try:\n",
    "                movie_data = self.get_movie_details(link)\n",
    "                data_list.append(movie_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {link}: {e}\")\n",
    "\n",
    "        self.driver.quit()\n",
    "        return pd.DataFrame(data_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = IMDbScraper()\n",
    "    action_movies_url = 'https://www.imdb.com/search/title/?genres=action&explore=genres&title_type=feature'\n",
    "    movie_df = scraper.scrape_movies(action_movies_url, num_links=50)\n",
    "    if movie_df.empty:\n",
    "        print(\"No data scraped.\")\n",
    "    else:\n",
    "        print(movie_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85bac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f6aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19f574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca452f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0bbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fd63f4",
   "metadata": {},
   "source": [
    "# Review Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "chrome_service = ChromeService()\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Open the webpage\n",
    "url = 'https://www.imdb.com/title/tt20215968/reviews?ref_=tt_urv'\n",
    "driver.get(url)\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# Function to extract reviews from the page\n",
    "def extract_reviews():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review_elements = soup.find_all('div', class_='lister-item-content')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        title = review_element.find('a', class_='title').text.strip()\n",
    "        date = review_element.find('span', class_='review-date').text.strip()\n",
    "        description = review_element.find('div', class_='text').text.strip()\n",
    "        rating_element = review_element.find('span', class_='rating-other-user-rating')\n",
    "        rating = rating_element.find('span').text.strip() if rating_element else 'N/A'\n",
    "\n",
    "        reviews.append({\n",
    "            'title': title,\n",
    "            'date': date,\n",
    "            'description': description,\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "# Load more reviews up to 8 times\n",
    "max_loads = 8\n",
    "for _ in range(max_loads):\n",
    "    try:\n",
    "        extract_reviews()\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'load-more-trigger'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)  # Wait for the new reviews to load\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Extract reviews from the last loaded page\n",
    "extract_reviews()\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert the reviews to a pandas DataFrame\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df.to_csv('reviews.csv', index=alse)\n",
    "\n",
    "print(\"Reviews saved to reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "chrome_service = ChromeService()\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Open the webpage\n",
    "url = 'https://www.imdb.com/title/tt20215968/reviews?ref_=tt_urv'\n",
    "driver.get(url)\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# Function to extract reviews from the page\n",
    "def extract_reviews():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review_elements = soup.find_all('div', class_='lister-item-content')\n",
    "\n",
    "    # Extract movie name and year\n",
    "    movie_info = soup.find('div', class_='parent').find('h3', itemprop='name')\n",
    "    movie_name = movie_info.find('a').text.strip()\n",
    "    movie_year = movie_info.find('span', class_='nobr').text.strip().strip('()')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        title = review_element.find('a', class_='title').text.strip()\n",
    "        date = review_element.find('span', class_='review-date').text.strip()\n",
    "        description = review_element.find('div', class_='text').text.strip()\n",
    "        rating_element = review_element.find('span', class_='rating-other-user-rating')\n",
    "        rating = rating_element.find('span').text.strip() if rating_element else 'N/A'\n",
    "\n",
    "        reviews.append({\n",
    "            'movie_name': movie_name,\n",
    "            'movie_year': movie_year,\n",
    "            'title': title,\n",
    "            'date': date,\n",
    "            'description': description,\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "# Load more reviews up to 8 times\n",
    "max_loads = 8\n",
    "for _ in range(max_loads):\n",
    "    try:\n",
    "        extract_reviews()\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'load-more-trigger'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)  # Wait for the new reviews to load\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Extract reviews from the last loaded page\n",
    "extract_reviews()\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert the reviews to a pandas DataFrame\n",
    "df = pd.DataFrame(reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
