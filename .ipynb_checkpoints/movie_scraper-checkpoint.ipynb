{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd7fc19-266e-443f-b4d9-1f9a36b1c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "chrome_service = ChromeService()\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Open the webpage\n",
    "url = 'https://www.imdb.com/title/tt20215968/reviews?ref_=tt_urv'\n",
    "driver.get(url)\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# Function to extract reviews from the page\n",
    "def extract_reviews():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review_elements = soup.find_all('div', class_='lister-item-content')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        title = review_element.find('a', class_='title').text.strip()\n",
    "        date = review_element.find('span', class_='review-date').text.strip()\n",
    "        description = review_element.find('div', class_='text').text.strip()\n",
    "        rating_element = review_element.find('span', class_='rating-other-user-rating')\n",
    "        rating = rating_element.find('span').text.strip() if rating_element else 'N/A'\n",
    "\n",
    "        reviews.append({\n",
    "            'title': title,\n",
    "            'date': date,\n",
    "            'description': description,\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "# Load more reviews up to 8 times\n",
    "max_loads = 8\n",
    "for _ in range(max_loads):\n",
    "    try:\n",
    "        extract_reviews()\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'load-more-trigger'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)  # Wait for the new reviews to load\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Extract reviews from the last loaded page\n",
    "extract_reviews()\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert the reviews to a pandas DataFrame\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df.to_csv('reviews.csv', index=alse)\n",
    "\n",
    "print(\"Reviews saved to reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf32f1fa-d0cc-4423-a0e1-abba62260848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unsatisfactory Ending</td>\n",
       "      <td>9 June 2024</td>\n",
       "      <td>Double murder and life goes on as if nothing h...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good, yet somehow far from great</td>\n",
       "      <td>9 June 2024</td>\n",
       "      <td>It is a good movie for a lazy Saturday evening...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not As Clever As It Thinks It Is</td>\n",
       "      <td>10 June 2024</td>\n",
       "      <td>The premise is very good: a mashup of romcom a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is a banausic Rom-Com, sans the comedy, wit...</td>\n",
       "      <td>8 June 2024</td>\n",
       "      <td>This was billed as a quirky, clever Rom-Com by...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Close, Ruined by Consistent Illogic</td>\n",
       "      <td>10 June 2024</td>\n",
       "      <td>So much of the dialogue contradicts itself, so...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Just terrible</td>\n",
       "      <td>12 June 2024</td>\n",
       "      <td>Can't believe the main character would be inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>A very bad and dangerous ending!</td>\n",
       "      <td>13 June 2024</td>\n",
       "      <td>The first half of the movie is nice and the ac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>It's promising, but 1 hours too long</td>\n",
       "      <td>8 June 2024</td>\n",
       "      <td>The movie starts very promising. Quite funny, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Average viewers will LOVE it!!</td>\n",
       "      <td>15 June 2024</td>\n",
       "      <td>I was so excited and what a confusing movie. F...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Anyone in charge of editing here?</td>\n",
       "      <td>16 June 2024</td>\n",
       "      <td>We were left wondering when this movie was goi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title          date  \\\n",
       "0                                 Unsatisfactory Ending   9 June 2024   \n",
       "1                      Good, yet somehow far from great   9 June 2024   \n",
       "2                      Not As Clever As It Thinks It Is  10 June 2024   \n",
       "3     It is a banausic Rom-Com, sans the comedy, wit...   8 June 2024   \n",
       "4                So Close, Ruined by Consistent Illogic  10 June 2024   \n",
       "...                                                 ...           ...   \n",
       "1120                                      Just terrible  12 June 2024   \n",
       "1121                   A very bad and dangerous ending!  13 June 2024   \n",
       "1122               It's promising, but 1 hours too long   8 June 2024   \n",
       "1123                     Average viewers will LOVE it!!  15 June 2024   \n",
       "1124                  Anyone in charge of editing here?  16 June 2024   \n",
       "\n",
       "                                            description rating  \n",
       "0     Double murder and life goes on as if nothing h...      7  \n",
       "1     It is a good movie for a lazy Saturday evening...      6  \n",
       "2     The premise is very good: a mashup of romcom a...      6  \n",
       "3     This was billed as a quirky, clever Rom-Com by...      6  \n",
       "4     So much of the dialogue contradicts itself, so...      6  \n",
       "...                                                 ...    ...  \n",
       "1120  Can't believe the main character would be inte...      1  \n",
       "1121  The first half of the movie is nice and the ac...      3  \n",
       "1122  The movie starts very promising. Quite funny, ...      3  \n",
       "1123  I was so excited and what a confusing movie. F...      5  \n",
       "1124  We were left wondering when this movie was goi...      5  \n",
       "\n",
       "[1125 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a4f5a-8547-4f5a-890c-2740d573694d",
   "metadata": {},
   "source": [
    "# Get review from particular link/movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b742c543-ec12-4263-a567-1315b4f61739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "chrome_service = ChromeService()\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Open the webpage\n",
    "url = 'https://www.imdb.com/title/tt20215968/reviews?ref_=tt_urv'\n",
    "driver.get(url)\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# Function to extract reviews from the page\n",
    "def extract_reviews():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review_elements = soup.find_all('div', class_='lister-item-content')\n",
    "\n",
    "    # Extract movie name and year\n",
    "    movie_info = soup.find('div', class_='parent').find('h3', itemprop='name')\n",
    "    movie_name = movie_info.find('a').text.strip()\n",
    "    movie_year = movie_info.find('span', class_='nobr').text.strip().strip('()')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        title = review_element.find('a', class_='title').text.strip()\n",
    "        date = review_element.find('span', class_='review-date').text.strip()\n",
    "        description = review_element.find('div', class_='text').text.strip()\n",
    "        rating_element = review_element.find('span', class_='rating-other-user-rating')\n",
    "        rating = rating_element.find('span').text.strip() if rating_element else 'N/A'\n",
    "\n",
    "        reviews.append({\n",
    "            'movie_name': movie_name,\n",
    "            'movie_year': movie_year,\n",
    "            'title': title,\n",
    "            'date': date,\n",
    "            'description': description,\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "# Load more reviews up to 8 times\n",
    "max_loads = 8\n",
    "for _ in range(max_loads):\n",
    "    try:\n",
    "        extract_reviews()\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'load-more-trigger'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)  # Wait for the new reviews to load\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Extract reviews from the last loaded page\n",
    "extract_reviews()\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Convert the reviews to a pandas DataFrame\n",
    "df = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78f4665b-2c08-4992-95d9-ddf76f932291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>Unsatisfactory Ending</td>\n",
       "      <td>9 June 2024</td>\n",
       "      <td>Double murder and life goes on as if nothing h...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>Good, yet somehow far from great</td>\n",
       "      <td>9 June 2024</td>\n",
       "      <td>It is a good movie for a lazy Saturday evening...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>Not As Clever As It Thinks It Is</td>\n",
       "      <td>10 June 2024</td>\n",
       "      <td>The premise is very good: a mashup of romcom a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>It is a banausic Rom-Com, sans the comedy, wit...</td>\n",
       "      <td>8 June 2024</td>\n",
       "      <td>This was billed as a quirky, clever Rom-Com by...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>When an ending nullifies any decent thing before</td>\n",
       "      <td>10 June 2024</td>\n",
       "      <td>I had to give this a 1 because its ending turn...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>Entertaining but I didn't love it as I would h...</td>\n",
       "      <td>29 January 2024</td>\n",
       "      <td>Watched this at the 2024 Sundance Film Festiva...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>The story doesn't really get anywhere</td>\n",
       "      <td>13 June 2024</td>\n",
       "      <td>Glen is incredible and the way he switches bet...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>It accomplishes nothing it sets out to do.</td>\n",
       "      <td>16 June 2024</td>\n",
       "      <td>I see you ordered the dark comedy on Netflix. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>Immorality Wins</td>\n",
       "      <td>12 June 2024</td>\n",
       "      <td>Lots of reviewers her are saying the same thin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Hit Man</td>\n",
       "      <td>2023</td>\n",
       "      <td>I could barely finish.</td>\n",
       "      <td>18 June 2024</td>\n",
       "      <td>I recently watched \"Hit Man,\" and to say it wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_name movie_year                                              title  \\\n",
       "0       Hit Man       2023                              Unsatisfactory Ending   \n",
       "1       Hit Man       2023                   Good, yet somehow far from great   \n",
       "2       Hit Man       2023                   Not As Clever As It Thinks It Is   \n",
       "3       Hit Man       2023  It is a banausic Rom-Com, sans the comedy, wit...   \n",
       "4       Hit Man       2023   When an ending nullifies any decent thing before   \n",
       "...         ...        ...                                                ...   \n",
       "1120    Hit Man       2023  Entertaining but I didn't love it as I would h...   \n",
       "1121    Hit Man       2023              The story doesn't really get anywhere   \n",
       "1122    Hit Man       2023         It accomplishes nothing it sets out to do.   \n",
       "1123    Hit Man       2023                                    Immorality Wins   \n",
       "1124    Hit Man       2023                             I could barely finish.   \n",
       "\n",
       "                 date                                        description  \\\n",
       "0         9 June 2024  Double murder and life goes on as if nothing h...   \n",
       "1         9 June 2024  It is a good movie for a lazy Saturday evening...   \n",
       "2        10 June 2024  The premise is very good: a mashup of romcom a...   \n",
       "3         8 June 2024  This was billed as a quirky, clever Rom-Com by...   \n",
       "4        10 June 2024  I had to give this a 1 because its ending turn...   \n",
       "...               ...                                                ...   \n",
       "1120  29 January 2024  Watched this at the 2024 Sundance Film Festiva...   \n",
       "1121     13 June 2024  Glen is incredible and the way he switches bet...   \n",
       "1122     16 June 2024  I see you ordered the dark comedy on Netflix. ...   \n",
       "1123     12 June 2024  Lots of reviewers her are saying the same thin...   \n",
       "1124     18 June 2024  I recently watched \"Hit Man,\" and to say it wa...   \n",
       "\n",
       "     rating  \n",
       "0         7  \n",
       "1         6  \n",
       "2         6  \n",
       "3         6  \n",
       "4       N/A  \n",
       "...     ...  \n",
       "1120      5  \n",
       "1121      5  \n",
       "1122      1  \n",
       "1123      5  \n",
       "1124      4  \n",
       "\n",
       "[1125 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24adaa-53b1-4916-b4a8-1de74c99f5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18404a1a-1ef7-4ebd-8dd2-70d3216627d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b84c6-35b2-48d7-9f62-5b0b63e7d24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bdc527d-f9ac-4f16-9c25-d906c7aee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_genres = ['action',\n",
    "                  'adventure',\n",
    "                  'animation',\n",
    "                  'biography',\n",
    "                  'comedy',\n",
    "                  'crime',\n",
    "                  'documentry',\n",
    "                  'drama',\n",
    "                  'family',\n",
    "                  'fantasy',\n",
    "                  'history',\n",
    "                  'horror',\n",
    "                  'music',\n",
    "                  'romance',\n",
    "                  'mystery',\n",
    "                  'thriller',\n",
    "                  'war',\n",
    "                  'western',\n",
    "                  'sport',\n",
    "                  'sci-fi',\n",
    "                  'game-show',\n",
    "                  'film-noir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f68a76-82b6-4ea0-8977-1cd9d54a46f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c713f9d-2552-4bea-b5bd-e43c6cff5aae",
   "metadata": {},
   "source": [
    "# Genere Links Gener Links Genere Links Genere Links Genere Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabe4487-7883-48e3-bf72-6a832b80426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromedriver_autoinstaller in c:\\users\\rajgo\\anaconda3\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\rajgo\\anaconda3\\lib\\site-packages (from chromedriver_autoinstaller) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b437fdd4-912f-43fc-8071-1f4e0103ce89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChromeService' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 5\u001b[0m chrome_service \u001b[38;5;241m=\u001b[39m ChromeService()\n\u001b[0;32m      6\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mchrome_service, options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Open the IMDb Action Movies page\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChromeService' is not defined"
     ]
    }
   ],
   "source": [
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "chrome_service = ChromeService()\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Open the IMDb Action Movies page\n",
    "url = 'https://www.imdb.com/search/title/?genres=action&explore=genres&title_type=feature'\n",
    "driver.get(url)\n",
    "\n",
    "movie_links = []\n",
    "\n",
    "# Function to extract movie links from the page\n",
    "def extract_movie_links():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "    for link_element in link_elements:\n",
    "        href = link_element['href']\n",
    "        full_url = f'https://www.imdb.com{href}'\n",
    "        if full_url not in movie_links:\n",
    "            movie_links.append(full_url)\n",
    "\n",
    "# Extract movie links\n",
    "extract_movie_links()\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364225ac-939c-4e30-86a6-76758652a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Automatically download and install the chromedriver executable\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run in headless mode (without a UI)\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "\n",
    "# Create a Chrome WebDriver service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Create a WebDriver instance\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Open the IMDb Action Movies page\n",
    "url = 'https://www.imdb.com/search/title/?genres=action&explore=genres&title_type=feature'\n",
    "driver.get(url)\n",
    "\n",
    "movie_links = []\n",
    "\n",
    "# Function to extract movie links from the page\n",
    "def extract_movie_links():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "    for link_element in link_elements:\n",
    "        href = link_element['href']\n",
    "        full_url = f'https://www.imdb.com{href}'\n",
    "        if full_url not in movie_links:\n",
    "            movie_links.append(full_url)\n",
    "\n",
    "# Extract movie links\n",
    "extract_movie_links()\n",
    "\n",
    "# Print the extracted movie links\n",
    "for link in movie_links:\n",
    "    print(link)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18face4e-3624-41ef-b761-72022e4e00c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646e9a1-070d-4246-a244-dd621b68511c",
   "metadata": {},
   "source": [
    "# 2. Movie Genres links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44f982ad-2446-4cdd-b50f-f52e9dbcf909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout waiting for https://www.imdb.com/search/title/?genres=documentry&explore=genres&title_type=feature to load\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException  # Import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "import time\n",
    "\n",
    "# Automatically install the correct version of chromedriver that matches the installed Chrome version\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Chrome options to set user-agent\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Function to extract movie links from a genre page\n",
    "def extract_movie_links(genre):\n",
    "    url = f'https://www.imdb.com/search/title/?genres={genre}&explore=genres&title_type=feature'\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Wait until at least one movie link element is visible\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'ipc-title-link-wrapper')))\n",
    "    except TimeoutException:\n",
    "        print(f'Timeout waiting for {url} to load')\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return []\n",
    "\n",
    "    time.sleep(2)  # Additional delay to ensure page stability\n",
    "    \n",
    "    movie_links = []\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "    \n",
    "    for link_element in link_elements:\n",
    "        href = link_element['href']\n",
    "        full_url = f'https://www.imdb.com{href}'\n",
    "        movie_id = href.split('/')[2].split('?')[0]  # Extract movie ID from URL\n",
    "        movie_links.append({\n",
    "            'Genre': genre,\n",
    "            'Movie ID': movie_id,\n",
    "            'Movie URL': full_url\n",
    "        })\n",
    "    \n",
    "    return movie_links\n",
    "\n",
    "# List of genres to scrape\n",
    "list_of_genres = ['action',\n",
    "                  'adventure',\n",
    "                  'animation',\n",
    "                  'biography',\n",
    "                  'comedy',\n",
    "                  'crime',\n",
    "                  'documentry',\n",
    "                  'drama',\n",
    "                  'family',\n",
    "                  'fantasy',\n",
    "                  'history',\n",
    "                  'horror',\n",
    "                  'music',\n",
    "                  'romance',\n",
    "                  'mystery',\n",
    "                  'thriller',\n",
    "                  'war',\n",
    "                  'western',\n",
    "                  'sport',\n",
    "                  'sci-fi',\n",
    "                  'game-show',\n",
    "                  'film-noir'] # Add more genres as needed\n",
    "\n",
    "# Data storage list\n",
    "data_list = []\n",
    "\n",
    "# Iterate over each genre and extract movie links\n",
    "for genre in list_of_genres:\n",
    "    genre_movie_links = extract_movie_links(genre)\n",
    "    data_list.extend(genre_movie_links)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "genre_links_df = pd.DataFrame(data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6b11b-aed2-4a1b-91c7-7c9699407833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "503bc5f5-8b90-4e23-9f5d-549e8408a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.imdb.com/title/tt4919268/?ref_=sr_t_1'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_links_df['Movie URL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d85bf-d63d-4e07-8f1c-91f102a8ecf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a66a0-2a33-4823-bb3f-75fdd0ebe683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6136061-5f71-461f-85d1-bca03f1e4865",
   "metadata": {},
   "source": [
    "# One movie one movie one movie one movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bfe9449-6ebe-44eb-aa07-1b6a630b45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "# List of URLs (example: movie_links should be defined)\n",
    "movie_links = [\n",
    "    \"https://www.imdb.com/title/tt0266697/?ref_=sr_t_49\",\n",
    "    # \"https://www.imdb.com/title/tt7286456/?ref_=ttls_li_tt\"\n",
    "]\n",
    "\n",
    "# Data storage list\n",
    "data_list = []\n",
    "\n",
    "for url in movie_links:\n",
    "    # Open the IMDb page for the movie\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait until the page title contains \"IMDb\"\n",
    "    WebDriverWait(driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Function to extract text including pseudo-elements\n",
    "    def get_text_with_pseudo(driver, element):\n",
    "        script = \"\"\"\n",
    "        var element = arguments[0];\n",
    "        var before = window.getComputedStyle(element, '::before').getPropertyValue('content');\n",
    "        var text = element.textContent;\n",
    "        return before.replace(/\"/g, '') + text;\n",
    "        \"\"\"\n",
    "        return driver.execute_script(script, element).strip()\n",
    "\n",
    "    # Extract the required information using BeautifulSoup\n",
    "    title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "    imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "    # Principal credits section\n",
    "    credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "\n",
    "    directors = []\n",
    "    for elem in credits_section[0].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            directors.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            directors.append('N/A')\n",
    "\n",
    "    writers = []\n",
    "    for elem in credits_section[1].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            writers.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            writers.append('N/A')\n",
    "\n",
    "    stars = []\n",
    "    for elem in credits_section[2].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            stars.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            stars.append('N/A')\n",
    "\n",
    "    storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "\n",
    "    # Release date with pseudo-element\n",
    "    release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "    release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "    origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "    languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "    budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "    gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "    runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "    # Extract genres\n",
    "    genres = []\n",
    "    genres_container = soup.find('div', {'data-testid': 'genres'})\n",
    "    if genres_container:\n",
    "        genre_links = genres_container.find_all('a')\n",
    "        genres = [link.text.strip() for link in genre_links]\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    movie_data = {\n",
    "        \"Title\": title,\n",
    "        \"IMDB Rating\": imdb_rating,\n",
    "        \"Directors\": \", \".join(directors),\n",
    "        \"Writers\": \", \".join(writers),\n",
    "        \"Stars\": \", \".join(stars),\n",
    "        \"Storyline\": storyline,\n",
    "        \"Release Date\": release_date,\n",
    "        \"Origin Countries\": \", \".join(origin_countries),\n",
    "        \"Languages\": \", \".join(languages),\n",
    "        \"Budget\": budget,\n",
    "        \"Gross Worldwide\": gross_worldwide,\n",
    "        \"Runtime\": runtime,\n",
    "        \"Genres\": \", \".join(genres)\n",
    "    }\n",
    "\n",
    "    # Append data to the list\n",
    "    data_list.append(movie_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786af90-c180-4f10-86db-341015c15bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c2fd3-0f48-43af-af3c-cd02d91989ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167877a8-e56c-481b-b97e-ec2eec1299c9",
   "metadata": {},
   "source": [
    "# ALL movie ALL movie ALL movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f62cf-bf33-4f47-bc7a-c9730154dc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93ee62e3-ea63-430f-a43c-5c68e5c6a2e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Wait until the page title contains \"IMDb\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mtitle_contains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the page source and parse it with BeautifulSoup\u001b[39;00m\n\u001b[0;32m     30\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "\n",
    "# Chrome service\n",
    "chrome_service = ChromeService()\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Data storage list\n",
    "data_list = []\n",
    "\n",
    "for url in movie_links:\n",
    "    # Open the IMDb page for the movie\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait until the page title contains \"IMDb\"\n",
    "    WebDriverWait(driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Function to extract text including pseudo-elements\n",
    "    def get_text_with_pseudo(driver, element):\n",
    "        script = \"\"\"\n",
    "        var element = arguments[0];\n",
    "        var before = window.getComputedStyle(element, '::before').getPropertyValue('content');\n",
    "        var text = element.textContent;\n",
    "        return before.replace(/\"/g, '') + text;\n",
    "        \"\"\"\n",
    "        return driver.execute_script(script, element).strip()\n",
    "\n",
    "    # Extract the required information using BeautifulSoup\n",
    "    title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "    imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "    # Principal credits section\n",
    "    credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "\n",
    "    directors = []\n",
    "    for elem in credits_section[0].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            directors.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            directors.append('N/A')\n",
    "\n",
    "    writers = []\n",
    "    for elem in credits_section[1].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            writers.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            writers.append('N/A')\n",
    "\n",
    "    stars = []\n",
    "    for elem in credits_section[2].find_all('a'):\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, f'//a[@href=\"{elem[\"href\"]}\"]')\n",
    "            stars.append(get_text_with_pseudo(driver, element))\n",
    "        except Exception as e:\n",
    "            stars.append('N/A')\n",
    "\n",
    "    storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "\n",
    "    # Release date with pseudo-element\n",
    "    release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "    release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "    origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "    languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "    budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "    gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "    runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "    # Extract genres\n",
    "    genres = []\n",
    "    genres_container = soup.find('div', {'data-testid': 'genres'})\n",
    "    if genres_container:\n",
    "        genre_links = genres_container.find_all('a')\n",
    "        genres = [link.text.strip() for link in genre_links]\n",
    "\n",
    "    # Store data in a dictionary\n",
    "    movie_data = {\n",
    "        \"Title\": title,\n",
    "        \"IMDB Rating\": imdb_rating,\n",
    "        \"Directors\": \", \".join(directors),\n",
    "        \"Writers\": \", \".join(writers),\n",
    "        \"Stars\": \", \".join(stars),\n",
    "        \"Storyline\": storyline,\n",
    "        \"Release Date\": release_date,\n",
    "        \"Origin Countries\": \", \".join(origin_countries),\n",
    "        \"Languages\": \", \".join(languages),\n",
    "        \"Budget\": budget,\n",
    "        \"Gross Worldwide\": gross_worldwide,\n",
    "        \"Runtime\": runtime,\n",
    "        \"Genres\": \", \".join(genres)\n",
    "    }\n",
    "\n",
    "    # Append data to the list\n",
    "    data_list.append(movie_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61962f-aeb9-4d7d-9a45-50c409efd67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19b53a-663b-4e07-90f7-b8c5f863b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20380ecf-9944-422d-905e-beec9da493ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438170a4-3ae2-4272-b791-aeb6f13cf62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30967f-ed62-497b-ad2b-8ba7ce68b325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2b5a9-6212-4e5e-9818-d0ea0ea10643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3f834-7ae7-46b2-b763-fe9b8e3c8485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11efa10-afd2-4bd2-85af-affe950242ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c20f2d56-84f7-4cb2-8359-2bbf4a2a44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No movie links found.\n",
      "No data scraped.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "class IMDbScraper:\n",
    "    def __init__(self):\n",
    "        # Chrome service and options\n",
    "        chromedriver_autoinstaller.install()\n",
    "        self.chrome_options = ChromeOptions()\n",
    "        self.chrome_options.add_argument(\"--headless\")  # Run in headless mode for faster execution\n",
    "        self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "\n",
    "    def fetch_action_movie_links(self, url, num_links=50):\n",
    "        self.driver.get(url)\n",
    "        movie_links = []\n",
    "        while len(movie_links) < num_links:\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            link_elements = soup.find_all('a', class_='ipc-title-link-wrapper')\n",
    "            for link_element in link_elements:\n",
    "                href = link_element['href']\n",
    "                full_url = f'https://www.imdb.com{href}'\n",
    "                if full_url not in movie_links:\n",
    "                    movie_links.append(full_url)\n",
    "                if len(movie_links) >= num_links:\n",
    "                    break\n",
    "            try:\n",
    "                next_button = self.driver.find_element(By.XPATH, \"//a[contains(text(),'Next Â»')]\")\n",
    "                next_button.click()\n",
    "            except:\n",
    "                break\n",
    "        return movie_links\n",
    "\n",
    "    def get_movie_details(self, url):\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "        title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "        imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "        credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "        directors = [a.text.strip() for a in credits_section[0].find_all('a')] if len(credits_section) > 0 else []\n",
    "        writers = [a.text.strip() for a in credits_section[1].find_all('a')] if len(credits_section) > 1 else []\n",
    "        stars = [a.text.strip() for a in credits_section[2].find_all('a')] if len(credits_section) > 2 else []\n",
    "\n",
    "        storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "        release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "        release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "        origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "        languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "        budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "        gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "        runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "        genres = [link.text.strip() for link in soup.find('div', {'data-testid': 'genres'}).find_all('a')] if soup.find('div', {'data-testid': 'genres'}) else []\n",
    "\n",
    "        movie_data = {\n",
    "            \"Title\": title,\n",
    "            \"IMDB Rating\": imdb_rating,\n",
    "            \"Directors\": \", \".join(directors),\n",
    "            \"Writers\": \", \".join(writers),\n",
    "            \"Stars\": \", \".join(stars),\n",
    "            \"Storyline\": storyline,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Origin Countries\": \", \".join(origin_countries),\n",
    "            \"Languages\": \", \".join(languages),\n",
    "            \"Budget\": budget,\n",
    "            \"Gross Worldwide\": gross_worldwide,\n",
    "            \"Runtime\": runtime,\n",
    "            \"Genres\": \", \".join(genres)\n",
    "        }\n",
    "\n",
    "        return movie_data\n",
    "\n",
    "    def scrape_movies(self, url, num_links=50):\n",
    "        movie_links = self.fetch_action_movie_links(url, num_links)\n",
    "        if not movie_links:\n",
    "            print(\"No movie links found.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data_list = []\n",
    "        for link in movie_links:\n",
    "            movie_data = self.get_movie_details(link)\n",
    "            data_list.append(movie_data)\n",
    "\n",
    "        self.driver.quit()\n",
    "        return pd.DataFrame(data_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = IMDbScraper()\n",
    "    action_movies_url = 'https://www.imdb.com/search/title/?genres=action&explore=genres&title_type=feature'\n",
    "    movie_df = scraper.scrape_movies(action_movies_url, num_links=50)\n",
    "    if movie_df.empty:\n",
    "        print(\"No data scraped.\")\n",
    "    else:\n",
    "        print(movie_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d141c-260c-4a69-a999-d7c2df17ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "class IMDbScraper:\n",
    "    def __init__(self):\n",
    "        chromedriver_autoinstaller.install()\n",
    "        self.chrome_options = ChromeOptions()\n",
    "        self.chrome_options.add_argument(\"--headless\")\n",
    "        self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "\n",
    "    def fetch_action_movie_links(self, url, num_links=50):\n",
    "        self.driver.get(url)\n",
    "        movie_links = []\n",
    "        while len(movie_links) < num_links:\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            link_elements = soup.select('h3.lister-item-header a')\n",
    "            for link_element in link_elements:\n",
    "                href = link_element['href']\n",
    "                full_url = f'https://www.imdb.com{href}'\n",
    "                if full_url not in movie_links:\n",
    "                    movie_links.append(full_url)\n",
    "                if len(movie_links) >= num_links:\n",
    "                    break\n",
    "            try:\n",
    "                next_button = self.driver.find_element(By.XPATH, \"//a[contains(text(),'Next Â»')]\")\n",
    "                next_button.click()\n",
    "            except Exception as e:\n",
    "                print(f\"Error finding next button or clicking it: {e}\")\n",
    "                break\n",
    "        return movie_links\n",
    "\n",
    "    def get_movie_details(self, url):\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 10).until(EC.title_contains(\"IMDb\"))\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "        title = soup.find('span', {'data-testid': 'hero__primary-text'}).text if soup.find('span', {'data-testid': 'hero__primary-text'}) else 'N/A'\n",
    "        imdb_rating = soup.find('span', class_='sc-bde20123-1').text if soup.find('span', class_='sc-bde20123-1') else 'N/A'\n",
    "\n",
    "        credits_section = soup.find_all('li', {'data-testid': 'title-pc-principal-credit'})\n",
    "        directors = [a.text.strip() for a in credits_section[0].find_all('a')] if len(credits_section) > 0 else []\n",
    "        writers = [a.text.strip() for a in credits_section[1].find_all('a')] if len(credits_section) > 1 else []\n",
    "        stars = [a.text.strip() for a in credits_section[2].find_all('a')] if len(credits_section) > 2 else []\n",
    "\n",
    "        storyline = soup.find('span', {'data-testid': 'plot-xl'}).text if soup.find('span', {'data-testid': 'plot-xl'}) else 'N/A'\n",
    "        release_date_elem = soup.find('li', {'data-testid': 'title-details-releasedate'}).find('a') if soup.find('li', {'data-testid': 'title-details-releasedate'}) else None\n",
    "        release_date = release_date_elem.text.strip() if release_date_elem else 'N/A'\n",
    "\n",
    "        origin_countries = [a.text for a in soup.find('li', {'data-testid': 'title-details-origin'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-origin'}) else []\n",
    "        languages = [a.text for a in soup.find('li', {'data-testid': 'title-details-languages'}).find_all('a')] if soup.find('li', {'data-testid': 'title-details-languages'}) else []\n",
    "        budget = soup.find('li', {'data-testid': 'title-boxoffice-budget'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-budget'}) else 'N/A'\n",
    "        gross_worldwide = soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text if soup.find('li', {'data-testid': 'title-boxoffice-cumulativeworldwidegross'}) else 'N/A'\n",
    "        runtime = soup.find('li', {'data-testid': 'title-techspec_runtime'}).find('div').text.strip() if soup.find('li', {'data-testid': 'title-techspec_runtime'}) else 'N/A'\n",
    "\n",
    "        genres = [link.text.strip() for link in soup.find('div', {'data-testid': 'genres'}).find_all('a')] if soup.find('div', {'data-testid': 'genres'}) else []\n",
    "\n",
    "        movie_data = {\n",
    "            \"Title\": title,\n",
    "            \"IMDB Rating\": imdb_rating,\n",
    "            \"Directors\": \", \".join(directors),\n",
    "            \"Writers\": \", \".join(writers),\n",
    "            \"Stars\": \", \".join(stars),\n",
    "            \"Storyline\": storyline,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Origin Countries\": \", \".join(origin_countries),\n",
    "            \"Languages\": \", \".join(languages),\n",
    "            \"Budget\": budget,\n",
    "            \"Gross Worldwide\": gross_worldwide,\n",
    "            \"Runtime\": runtime,\n",
    "            \"Genres\": \", \".join(genres)\n",
    "        }\n",
    "\n",
    "        return movie_data\n",
    "\n",
    "    def scrape_movies(self, url, num_links=50):\n",
    "        movie_links = self.fetch_action_movie_links(url, num_links)\n",
    "        if not movie_links:\n",
    "            print(\"No movie links found.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data_list = []\n",
    "        for link in movie_links:\n",
    "            try:\n",
    "                movie_data = self.get_movie_details(link)\n",
    "                data_list.append(movie_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {link}: {e}\")\n",
    "\n",
    "        self.driver.quit()\n",
    "        return pd.DataFrame(data_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = IMDbScraper()\n",
    "    action_movies_url = 'https://www.imdb.com/search/title/?genres=action&explore=genres&title_type=feature'\n",
    "    movie_df = scraper.scrape_movies(action_movies_url, num_links=50)\n",
    "    if movie_df.empty:\n",
    "        print(\"No data scraped.\")\n",
    "    else:\n",
    "        print(movie_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
